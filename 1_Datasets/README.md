# Datasets
To fully replicate the results, the comma.ai 2016 ([GitHub](https://github.com/commaai/research) [archive](https://archive.org/details/comma-dataset)), comma.ai 2k19 ([GitHub](https://github.com/commaai/comma2k19)) , and JUtah ([YouTube](https://www.youtube.com/@jutah)) datasets must be separately downloaded and set up.
These cannot be independently hosted due to licensing limitations and must be obtained from their original source.
Please reach out to one of the authors to obtain the original copies used for the paper: `hildebrandt.carl@virginia.edu` or `adw8dm@virginia.edu`.
The main README has more information on how to replicate the results from the paper using solely the outputs of the AV systems and the SUT.

The datasets should be unpacked into each of the individual subdirectories `1_Datasets/Data`:
* `OpenPilot_2016/0_OriginalData/`
* `OpenPilot_2k19/0_OriginalData/`
* `External_jutah/0_OriginalData/`

These folders have been added to the git repository by including a `delete_me.md` placeholder.
Please delete this file in each folder before continuing.

